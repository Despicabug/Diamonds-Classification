{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\") # Ignore all warnings\npd.set_option('display.max_columns', None) \npd.set_option('display.max_rows', 10) # Display Max 10 Rows","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-17T17:30:56.727261Z","iopub.execute_input":"2022-01-17T17:30:56.727688Z","iopub.status.idle":"2022-01-17T17:30:56.764332Z","shell.execute_reply.started":"2022-01-17T17:30:56.727577Z","shell.execute_reply":"2022-01-17T17:30:56.763739Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Read the CSV data into dataframe\n\ndf_cushion = pd.read_csv('../input/natural-diamonds-prices-images/Diamonds/Diamonds/data_cushion.csv')\ndf_emerald = pd.read_csv('../input/natural-diamonds-prices-images/Diamonds/Diamonds/data_emerald.csv')\ndf_heart = pd.read_csv('../input/natural-diamonds-prices-images/Diamonds/Diamonds/data_heart.csv')\ndf_oval = pd.read_csv('../input/natural-diamonds-prices-images/Diamonds/Diamonds/data_oval.csv')\ndf_radiant = pd.read_csv('../input/natural-diamonds-prices-images/Diamonds/Diamonds/data_radiant.csv')\ndf_round = pd.read_csv('../input/natural-diamonds-prices-images/Diamonds/Diamonds/data_round.csv')\n\ndf_cushion.drop(['Shape'], axis=1, inplace=True) \ndf_emerald.drop(['Shape'], axis=1, inplace=True) \ndf_heart.drop(['Shape'], axis=1, inplace=True) \ndf_oval.drop(['Shape'], axis=1, inplace=True) \ndf_radiant.drop(['Shape'], axis=1, inplace=True) \ndf_round.drop(['Shape'], axis=1, inplace=True) \n\nframes = [df_cushion,df_heart, df_radiant]\ndf = pd.concat(frames)\n\ndf_oval['Price'].dtypes\n\ndf\n","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:30:56.767302Z","iopub.execute_input":"2022-01-17T17:30:56.767603Z","iopub.status.idle":"2022-01-17T17:30:56.945845Z","shell.execute_reply.started":"2022-01-17T17:30:56.767570Z","shell.execute_reply":"2022-01-17T17:30:56.944985Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Convert Price to float from string\ndf['Price'] = df['Price'].str.replace(',', '').astype(np.float)\n\nframes = [df_emerald, df_oval, df_round]\n\ndf = pd.concat(frames)\n\n# Function to return all numbers as an array\ndef getNumbers(str):\n    import re\n    \n    array = re.findall(r'[0-9]', str)\n    return array\n\n# Convert Messurements to a usable string\ndf['Messurements'] = df['Messurements'].apply(lambda x: getNumbers(x) )\ndf['Messurements'] = df['Messurements'].apply(lambda x: ''.join(x) )\n\n# Derive new Attributes from the Messurements attribute\ndf['length']= df['Messurements'].str[:3].astype(np.float) /100\ndf['width'] = df['Messurements'].str[3:6].astype(np.float) /100\ndf['depth'] = df['Messurements'].str[6:].astype(np.float) / 100\n\ndf","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:30:56.946944Z","iopub.execute_input":"2022-01-17T17:30:56.947249Z","iopub.status.idle":"2022-01-17T17:30:56.996921Z","shell.execute_reply.started":"2022-01-17T17:30:56.947218Z","shell.execute_reply":"2022-01-17T17:30:56.996093Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def EDA(df):\n    print('\\033[1m' + 'Shape of the data :' + '\\033[0m')\n    print(df.shape, \n          '\\n------------------------------------------------------------------------------------\\n')\n    \n    print('\\033[1m' + 'All columns from the dataframe :' + '\\033[0m')\n    print(df.columns, \n          '\\n------------------------------------------------------------------------------------\\n')\n    \n    print('\\033[1m' + 'Datatpes and Missing values:' + '\\033[0m')\n    print(df.info(), \n          '\\n------------------------------------------------------------------------------------\\n')\n    \n    print('\\033[1m' + 'Missing value count:' + '\\033[0m')\n    print(df.isnull().sum(),\n          '\\n------------------------------------------------------------------------------------\\n')\n    \n    print('\\033[1m' + 'Summary statistics for the data' + '\\033[0m')\n    print(df.describe(include='all'), \n          '\\n------------------------------------------------------------------------------------\\n')\n    \n    print('\\033[1m' + 'Outliers in the data :' + '\\033[0m')\n    Q1 = df.quantile(0.25)\n    Q3 = df.quantile(0.75)\n    IQR = Q3 - Q1\n    outliers = (df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))\n    print(outliers.sum(), \n          '\\n------------------------------------------------------------------------------------\\n')\n        \n    print('\\033[1m' + 'Memory used by the data :' + '\\033[0m')\n    print(df.memory_usage(), \n          '\\n------------------------------------------------------------------------------------\\n')\n    \n    print('\\033[1m' + 'Number of duplicate values :' + '\\033[0m')\n    print(df.duplicated().sum())\n    \nEDA(df)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:30:56.998333Z","iopub.execute_input":"2022-01-17T17:30:56.998803Z","iopub.status.idle":"2022-01-17T17:30:57.094627Z","shell.execute_reply.started":"2022-01-17T17:30:56.998759Z","shell.execute_reply":"2022-01-17T17:30:57.093787Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Remove parameters unecessary to prediction\ndf = df.drop(['Id', 'Messurements', 'Data Url'], axis=1)\ndf.columns\n","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:30:57.096936Z","iopub.execute_input":"2022-01-17T17:30:57.097898Z","iopub.status.idle":"2022-01-17T17:30:57.106131Z","shell.execute_reply.started":"2022-01-17T17:30:57.097853Z","shell.execute_reply":"2022-01-17T17:30:57.105139Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Split features used for prediction and label to train data\nfeatures = df[ \n    ['Clarity',\n     'Weight',\n     'Colour',\n     'Polish',\n     'Cut',\n     'Symmetry',\n     'Fluorescence',\n     'length',\n     'width',\n     'depth',\n     ]\n]\n\n# Each price becomes a unique label \nlabels= df['Price']\nfeatures","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:30:57.107171Z","iopub.execute_input":"2022-01-17T17:30:57.107619Z","iopub.status.idle":"2022-01-17T17:30:57.136853Z","shell.execute_reply.started":"2022-01-17T17:30:57.107579Z","shell.execute_reply":"2022-01-17T17:30:57.136138Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(pd.get_dummies( features ), labels, test_size=0.2, random_state=0)\n\nX_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=0)\n\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:30:57.138034Z","iopub.execute_input":"2022-01-17T17:30:57.138429Z","iopub.status.idle":"2022-01-17T17:30:58.205220Z","shell.execute_reply.started":"2022-01-17T17:30:57.138387Z","shell.execute_reply":"2022-01-17T17:30:58.204271Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# Min Max normalisation over the training data\nscaler = MinMaxScaler()\nscaler.fit(X_train)\n\n# Scale the training, test, and validation sets\nfeatures = X_train.columns\n\nX_train[features] = scaler.transform(X_train[features])\nX_val[features] = scaler.transform(X_val[features])\nX_test[features] = scaler.transform(X_test[features])\n\nX_train.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:30:58.206318Z","iopub.execute_input":"2022-01-17T17:30:58.206582Z","iopub.status.idle":"2022-01-17T17:30:58.281362Z","shell.execute_reply.started":"2022-01-17T17:30:58.206552Z","shell.execute_reply":"2022-01-17T17:30:58.280417Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def correlation_heat_map(data, title, zmin=-1, zmax=1, height=600, width= 800):\n    \"\"\"\n    data: Your dataframe.\n    title: Title for the correlation matrix.\n    zmin: Minimum number for color scale. (-1 to 1). \n    zmax: Maximum number for color scale. (-1 to 1). \n    height: height of diplayed map.\n    width: width of diplayed map.\n    \"\"\"\n    \n    # Pairwise correlation of all features\n    data = data.corr()\n    mask = np.triu(np.ones_like(data, dtype=bool))\n    rLT = data.mask(mask)\n\n    heat = go.Heatmap(\n        z = rLT,\n        x = rLT.columns.values,\n        y = rLT.columns.values,\n        zmin = zmin, \n            # Sets the lower bound of the color domain\n        zmax = zmax,\n            # Sets the upper bound of color domain\n        xgap = 1, # Sets the horizontal gap (in pixels) between bricks\n        ygap = 1,\n        colorscale = 'Greens'\n    )\n\n    title = title\n\n    layout = go.Layout(\n        title_text=title, \n        title_x=0.5, \n        width= width, \n        height= height,\n        xaxis_showgrid=False,\n        yaxis_showgrid=False,\n        yaxis_autorange='reversed'\n    )\n\n    fig= go.Figure(data=[heat], layout=layout)\n    return fig","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:30:58.282444Z","iopub.execute_input":"2022-01-17T17:30:58.282870Z","iopub.status.idle":"2022-01-17T17:30:58.290596Z","shell.execute_reply.started":"2022-01-17T17:30:58.282836Z","shell.execute_reply":"2022-01-17T17:30:58.289536Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"Xy_train = pd.concat([X_train, y_train], axis=1)\n\ncorrelation_heat_map(Xy_train,'Correlation Map', height=1500, width=1500)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:30:58.292124Z","iopub.execute_input":"2022-01-17T17:30:58.292588Z","iopub.status.idle":"2022-01-17T17:30:58.486603Z","shell.execute_reply.started":"2022-01-17T17:30:58.292545Z","shell.execute_reply":"2022-01-17T17:30:58.485795Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nrfr = RandomForestRegressor(n_estimators=100, oob_score=True)\nrfr_model = rfr.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:30:58.487929Z","iopub.execute_input":"2022-01-17T17:30:58.488688Z","iopub.status.idle":"2022-01-17T17:30:59.743611Z","shell.execute_reply.started":"2022-01-17T17:30:58.488639Z","shell.execute_reply":"2022-01-17T17:30:59.742875Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize= (18, 45))\n\nfeature_importance = rfr.feature_importances_\nindices = np.argsort(feature_importance)\n\n\nplt.yticks(range(len(indices)), [X_train.columns[i] for i in indices])\nplt.barh(range(len(indices)), feature_importance[indices],color='orange' ,align='center')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:30:59.744794Z","iopub.execute_input":"2022-01-17T17:30:59.745015Z","iopub.status.idle":"2022-01-17T17:31:00.428370Z","shell.execute_reply.started":"2022-01-17T17:30:59.744989Z","shell.execute_reply":"2022-01-17T17:31:00.427531Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print('Accuracy for Train:', rfr.score(X_train, y_train) )\nprint('Accuracy for Test:', rfr.score(X_test, y_test) )","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:31:00.429426Z","iopub.execute_input":"2022-01-17T17:31:00.429833Z","iopub.status.idle":"2022-01-17T17:31:00.511627Z","shell.execute_reply.started":"2022-01-17T17:31:00.429760Z","shell.execute_reply":"2022-01-17T17:31:00.511034Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Make predictions for the test set\ny_pred = rfr_model.predict(X_test)\n\npred_res =pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})\npred_res","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:31:00.515722Z","iopub.execute_input":"2022-01-17T17:31:00.515954Z","iopub.status.idle":"2022-01-17T17:31:00.554415Z","shell.execute_reply.started":"2022-01-17T17:31:00.515927Z","shell.execute_reply":"2022-01-17T17:31:00.553662Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\n\n# Print out the mean absolute error (MAE)\nprint('Mean Absolute Error:', round( metrics.mean_absolute_error(y_test, y_pred),2 ))\nprint('Mean Squared Error:', round( metrics.mean_squared_error(y_test, y_pred), 2))\n\n# Calculate mean absolute percentage error (MAPE)\nerrors = abs(y_pred - y_test)\nmape = 100 * (errors / y_test)\n\n# Calculate and display accuracy\naccuracy = 100 - np.mean(mape)\nprint('Accuracy:', round(accuracy, 2), '%.')","metadata":{"execution":{"iopub.status.busy":"2022-01-17T17:31:00.555623Z","iopub.execute_input":"2022-01-17T17:31:00.556055Z","iopub.status.idle":"2022-01-17T17:31:00.566190Z","shell.execute_reply.started":"2022-01-17T17:31:00.556020Z","shell.execute_reply":"2022-01-17T17:31:00.565241Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}